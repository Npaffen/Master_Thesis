\babel@toc {english}{}\relax 
\babel@toc {english}{}\relax 
\contentsline {figure}{\numberline {1}{\ignorespaces Diagram of the working process of the Strava scraper. All user interactions are marked by full line arrows, all automized interactions by the Strava scraper are highlighted by coloured dotted arrows. Colours were added just for visual purpose. "*" - signs at the end of a description indicate that this process interacts with Strava.com. Therefore a sleep time after each url call is used to prevent a timeout.\relax }}{4}{figure.caption.6}%
\contentsline {figure}{\numberline {2}{\ignorespaces Heat map for the dataset with average power and dropped NA values.\relax }}{9}{figure.caption.8}%
\contentsline {figure}{\numberline {3}{\ignorespaces Decision Tree Example for the Strava irmi dataset\relax }}{12}{figure.caption.9}%
\contentsline {figure}{\numberline {4}{\ignorespaces Diagram of a random forest prediction example. A new observation is shown to the model and each tree gives its prediction on the target variable, here $type$, of the Strava dataset. The figure is just for clarification of the concept and does not necessarily represent a possible outcome of a random forest model. \relax }}{13}{figure.caption.10}%
\contentsline {figure}{\numberline {5}{\ignorespaces The diagram shows exemplary how GBM calculates the predictions.\relax }}{16}{figure.caption.11}%
\contentsline {figure}{\numberline {6}{\ignorespaces The diagram shows exemplary how XGBoost initiates the algorithm, builds trees, calculates the weights and updates the model.\relax }}{20}{figure.caption.12}%
\contentsline {figure}{\numberline {7}{\ignorespaces The diagram shows how the orderd boosting algorithm in CatBoost works.\relax }}{23}{figure.caption.13}%
\contentsline {figure}{\numberline {8}{\ignorespaces Examplary Gaussian Process for a single Hyperparameter\relax }}{28}{figure.caption.16}%
\contentsline {figure}{\numberline {9}{\ignorespaces OOS results for model 3\relax }}{39}{figure.caption.23}%
\contentsline {figure}{\numberline {10}{\ignorespaces This figure shows the feature importance defined by the absolute mean Shapley values of each variable of model 3 fitted with the XGBoost algorithm. All values were calculated from the test dataset. For \relax }}{40}{figure.caption.24}%
\contentsline {figure}{\numberline {11}{\ignorespaces This figure shows the summary of each variable with respect to each observation of model 3 fitted with the Catboost algorithm. All values were calculated from the test dataset. \relax }}{42}{figure.caption.25}%
\contentsline {figure}{\numberline {12}{\ignorespaces OOS results for UCI weekly points prediction with model 1 and 2\relax }}{43}{figure.caption.26}%
\contentsline {figure}{\numberline {13}{\ignorespaces OOS results for UCI weekly points prediction with model 3 and 4\relax }}{44}{figure.caption.27}%
\contentsline {figure}{\numberline {14}{\ignorespaces This figure shows a feature decision plot of each variable of model 1 fitted with the Lightgbm algorithm predicting the UCI weekly points. All values were calculated from the first 10.000 observations the test dataset. \relax }}{45}{figure.caption.28}%
\contentsline {figure}{\numberline {15}{\ignorespaces This figure shows the summary of each variable with respect to each observation of model 1 fitted with the Lightgbm algorithm predicting the UCI weekly points. All values were calculated from the test dataset.\relax }}{46}{figure.caption.29}%
\contentsline {figure}{\numberline {16}{\ignorespaces results for UCI weekly points prediction with model 1 and 2 without \(height\), \(season\), \(age\), \(avg\_calories\) and \(avg\_elap\_time\_sec\)\relax }}{48}{figure.caption.30}%
\contentsline {figure}{\numberline {17}{\ignorespaces results for UCI weekly points prediction with model 3 and 3 without \(height\), \(season\), \(age\), \(avg\_calories\) and \(avg\_elap\_time\_sec\)\relax }}{49}{figure.caption.31}%
\contentsline {figure}{\numberline {18}{\ignorespaces Diagram of the two tree versions of the simple model $Y = 100 \times X_1 + 100 \times X_1$. The values with a green number representing the subset of the dataset at a given split while the numbers in the leave nodes representing the value of the leaves.\relax }}{52}{figure.caption.38}%
\contentsline {figure}{\numberline {19}{\ignorespaces The picture shows the user-interface of the Straver Scraper v.1.0\relax }}{60}{figure.caption.44}%
